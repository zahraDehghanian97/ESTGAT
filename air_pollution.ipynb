{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "air pollution.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/air-pollution/blob/master/air_pollution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import torch; print(torch.__version__)\"\n",
        "!python -c \"import torch; print(torch.version.cuda)\"\n",
        "!pip -q install torch-spline-conv==latest+cu102 torch-scatter==latest+cu102 torch-cluster==latest+cu102 torch-sparse==latest+cu102 torch-geometric  -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n",
        "!pip -q install torch-geometric-temporal"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:44:24.749526Z",
          "iopub.execute_input": "2021-12-24T18:44:24.749856Z",
          "iopub.status.idle": "2021-12-24T18:45:02.742176Z",
          "shell.execute_reply.started": "2021-12-24T18:44:24.749821Z",
          "shell.execute_reply": "2021-12-24T18:45:02.741249Z"
        },
        "trusted": true,
        "id": "rLtniey2xXhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>\n",
        "<center>Attention Based Spatial-Temporal Graph Convolutional Networks\n",
        "for Information diffusion prediction</center>\n",
        "</h1>\n"
      ],
      "metadata": {
        "id": "89tf8kS-xXhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will dive into attentional temporal graph convolution networks where everything new meets Attention + deep learning time series analysis( temporal data) + Graph convolution all in one thing"
      ],
      "metadata": {
        "id": "M_e55AcJxXh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from scipy.sparse.linalg import eigs\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device('cuda:0')\n",
        "print(\"CUDA:\", USE_CUDA, DEVICE)\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "sw = SummaryWriter(logdir='.', flush_secs=5)\n",
        "\n",
        "import math\n",
        "from typing import Optional, List, Union\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.typing import OptTensor\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.transforms import LaplacianLambdaMax\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, get_laplacian\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from torch_scatter import scatter_add"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:02.744355Z",
          "iopub.execute_input": "2021-12-24T18:45:02.744722Z",
          "iopub.status.idle": "2021-12-24T18:45:05.398805Z",
          "shell.execute_reply.started": "2021-12-24T18:45:02.744681Z",
          "shell.execute_reply": "2021-12-24T18:45:05.397902Z"
        },
        "trusted": true,
        "id": "9TlHxVQPxXh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the graph adjacency matrix (Spatial part)\n",
        "We used 84 countries which are connected if they share borders."
      ],
      "metadata": {
        "id": "NEHu3MVfxXh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../input/geocov19-data-preparation/Adj_matrix.npy', 'rb') as f:\n",
        "    adj_mx = np.load(f) #  adj_mx  (84, 84)\n",
        "    \n",
        "rows, cols = np.where(adj_mx == 1)\n",
        "edges = zip(rows.tolist(), cols.tolist())\n",
        "gr = nx.Graph()\n",
        "gr.add_edges_from(edges)\n",
        "nx.draw(gr, node_size=3)\n",
        "plt.show()\n",
        "\n",
        "rows, cols = np.where(adj_mx == 1)\n",
        "edges = zip(rows.tolist(), cols.tolist())\n",
        "edge_index_data = torch.LongTensor(np.array([rows, cols])).to(DEVICE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:05.400319Z",
          "iopub.execute_input": "2021-12-24T18:45:05.400666Z",
          "iopub.status.idle": "2021-12-24T18:45:35.56826Z",
          "shell.execute_reply.started": "2021-12-24T18:45:05.400626Z",
          "shell.execute_reply": "2021-12-24T18:45:35.567421Z"
        },
        "trusted": true,
        "id": "LsvxnLFgxXiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the data (Temporal part)\n",
        "\n",
        "As discussed in the previous notebook, the data(91 days) from 84 countries is splitted as follows:\n",
        "\n",
        "The first ( 70 days )  will be used as the training set \n",
        "\n",
        "The next ( 11 days )  will be used as the validation set\n",
        "\n",
        "The last ( 10 days ) will be used as the testing set\n",
        "\n",
        "The prediction task is to use the data from the last three days (#example, 84, 1, 72) to predict the fourth day (#example, 84, 24)  , As the data will be loaded in batches of size 32, we can add the batch dimention before the #example dimention."
      ],
      "metadata": {
        "id": "OkJZYHBdxXiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../input/geocov19-data-preparation/tweets_data_previous_hours_train.npy', 'rb') as f:\n",
        "    tweets_data_previous_hours_train = np.load(f)\n",
        "with open('../input/geocov19-data-preparation/tweets_data_target_train.npy', 'rb') as f:\n",
        "    tweets_data_target_train = np.load(f)\n",
        "\n",
        "with open('../input/geocov19-data-preparation/tweets_data_previous_hours_val.npy', 'rb') as f:\n",
        "    tweets_data_previous_hours_val = np.load(f)\n",
        "with open('../input/geocov19-data-preparation/tweets_data_target_val.npy', 'rb') as f:\n",
        "    tweets_data_target_val = np.load(f)\n",
        "\n",
        "with open('../input/geocov19-data-preparation/tweets_data_previous_hours_test.npy', 'rb') as f:\n",
        "    tweets_data_previous_hours_test = np.load(f)\n",
        "with open('../input/geocov19-data-preparation/tweets_data_target_test.npy', 'rb') as f:\n",
        "    tweets_data_target_test = np.load(f)\n",
        "    \n",
        "\n",
        "tweets_data_previous_hours_train = np.transpose(np.expand_dims(tweets_data_previous_hours_train,-1), (0, 2, 3, 1))\n",
        "tweets_data_target_train = np.transpose(tweets_data_target_train,(0,2,1))\n",
        "\n",
        "tweets_data_previous_hours_val = np.transpose(np.expand_dims(tweets_data_previous_hours_val,-1), (0, 2, 3, 1))\n",
        "tweets_data_target_val = np.transpose(tweets_data_target_val,(0,2,1))\n",
        "\n",
        "tweets_data_previous_hours_test = np.transpose(np.expand_dims(tweets_data_previous_hours_test,-1), (0, 2, 3, 1))\n",
        "tweets_data_target_test = np.transpose(tweets_data_target_test,(0,2,1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:35.569649Z",
          "iopub.execute_input": "2021-12-24T18:45:35.569992Z",
          "iopub.status.idle": "2021-12-24T18:45:39.118949Z",
          "shell.execute_reply.started": "2021-12-24T18:45:35.569956Z",
          "shell.execute_reply": "2021-12-24T18:45:39.118148Z"
        },
        "trusted": true,
        "id": "77pPp7UIxXiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the DataLoaders"
      ],
      "metadata": {
        "id": "MKlXLpsjxXiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle=True\n",
        "DEVICE = torch.device('cuda:0')\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "train_x_tensor = torch.from_numpy(tweets_data_previous_hours_train).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "train_target_tensor = torch.from_numpy(tweets_data_target_train).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "train_dataset = torch.utils.data.TensorDataset(train_x_tensor, train_target_tensor)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "\n",
        "val_x_tensor = torch.from_numpy(tweets_data_previous_hours_val).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "val_target_tensor = torch.from_numpy(tweets_data_target_val).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "val_dataset = torch.utils.data.TensorDataset(val_x_tensor, val_target_tensor)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "\n",
        "test_x_tensor = torch.from_numpy(tweets_data_previous_hours_test).type(torch.FloatTensor).to(DEVICE)  # (B, N, F, T)\n",
        "test_target_tensor = torch.from_numpy(tweets_data_target_test).type(torch.FloatTensor).to(DEVICE)  # (B, N, T)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_x_tensor, test_target_tensor)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "print('train:', train_x_tensor.size(), train_target_tensor.size())\n",
        "print('valid:', val_x_tensor.size(), val_target_tensor.size())\n",
        "print('test:', test_x_tensor.size(), test_target_tensor.size())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.122679Z",
          "iopub.execute_input": "2021-12-24T18:45:39.123037Z",
          "iopub.status.idle": "2021-12-24T18:45:39.173818Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.123001Z",
          "shell.execute_reply": "2021-12-24T18:45:39.173113Z"
        },
        "trusted": true,
        "id": "EgkD9KEixXiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Model Layers"
      ],
      "metadata": {
        "id": "X6azJyIvxXiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Temporal attention layer\n",
        "\n",
        "In the temporal dimension, there exist correlations between the traffic conditions in different time slices, and the correlations are also varying under different situations. Likewise, we use an attention mechanism to adaptively attach different importance to data. \n",
        "\n",
        "<img src=\"attachment:d221eddd-c1e0-4242-8dbb-bf1b0b4cb1d0.png\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "kzWZ86WkxXiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand the equation :\n",
        "\n",
        "It learns to attend (focus) on which part of the time segement used as input. In our case we have 12 time points So it will generate 12 by 12 weights. \n",
        "\n",
        "<img src=\"https://i.ibb.co/NZ4fh4k/atten2.jpg\" width=\"400\">\n",
        "\n"
      ],
      "metadata": {
        "id": "HmbItWgNxXiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TemporalAttention(nn.Module):\n",
        "    r\"\"\"An implementation of the Temporal Attention Module. For details see this paper:\n",
        "    `\"Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow\n",
        "    Forecasting.\" <https://ojs.aaai.org/index.php/AAAI/article/view/3881>`_\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        num_of_vertices (int): Number of vertices in the graph.\n",
        "        num_of_timesteps (int): Number of time lags.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels: int, num_of_vertices: int, num_of_timesteps: int, DEVICE = torch.device('cuda:0')):\n",
        "        super(TemporalAttention, self).__init__()\n",
        "\n",
        "        self._U1 = nn.Parameter(torch.cuda.FloatTensor(num_of_vertices))  # 307\n",
        "        self._U2 = nn.Parameter(torch.cuda.FloatTensor(in_channels, num_of_vertices)) #(1, 307)\n",
        "        self._U3 = nn.Parameter(torch.cuda.FloatTensor(in_channels)) # (1)\n",
        "        self._be = nn.Parameter( torch.cuda.FloatTensor(1, num_of_timesteps, num_of_timesteps))   # (1,12,12 )\n",
        "        self._Ve = nn.Parameter(torch.cuda.FloatTensor(num_of_timesteps, num_of_timesteps))  # (12, 12)\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "            else:\n",
        "                nn.init.uniform_(p)\n",
        "                \n",
        "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Making a forward pass of the temporal attention layer.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (PyTorch FloatTensor) - Node features for T time periods, with shape (B, N_nodes, F_in, T_in).\n",
        "\n",
        "        Return types:\n",
        "            * **E** (PyTorch FloatTensor) - Temporal attention score matrices, with shape (B, T_in, T_in).\n",
        "        \"\"\"\n",
        "         # (32, 307, 1, 12) -premute-> (32, 12, 1, 307) * (307) -> (32, 12, 1) * (1, 307) \n",
        "\n",
        "        LHS = torch.matmul(torch.matmul(X.permute(0, 3, 2, 1), self._U1), self._U2) # (32, 12, 307) # one signal (mean of all detectors) for each timestamp then regenerate them\n",
        "        # x:(B, N, F_in, T) -> (B, T, F_in, N)  lhs = left hand side embedding; rhs = right hand side embedding\n",
        "        # (B, T, F_in, N)(N) -> (B,T,F_in)\n",
        "        # (B,T,F_in)(F_in,N)->(B,T,N)\n",
        "\n",
        "        \n",
        "        RHS = torch.matmul(self._U3, X)   # (F)(B,N,F,T)->(B, N, T) (1)(32, 307, 1, 12) -> (32, 307, 12) # one feature (mean of all features) for each detector\n",
        "        E = torch.matmul(self._Ve, torch.sigmoid(torch.matmul(LHS, RHS) + self._be)) # (B,T,N)(B,N,T)->(B,T,T) (32, 12, 307) * (32, 307, 12) -> (32, 12, 12) \n",
        "        #  (B, T, T)  (32, 12, 12)\n",
        "        E = F.softmax(E, dim=1) # (32, 12, 12)\n",
        "        return E"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.177184Z",
          "iopub.execute_input": "2021-12-24T18:45:39.177437Z",
          "iopub.status.idle": "2021-12-24T18:45:39.19182Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.177412Z",
          "shell.execute_reply": "2021-12-24T18:45:39.190856Z"
        },
        "trusted": true,
        "id": "dnholxXjxXiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial attention layer\n",
        "\n",
        "In the spatial dimension, the traffic conditions of different locations have influence among each other and the mutual influence is highly dynamic. Here, we use an attention mechanism (Feng et al. 2017) to adaptively capture the dynamic correlations between nodes in the spatial dimension.\n",
        "\n",
        "<img src=\"https://i.ibb.co/PGnj4MR/spatial1.png\" width=\"400\">\n",
        "\n",
        "<img src=\"https://i.ibb.co/G5jkKvr/spatial2.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "ECOtpOK-xXiM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same as with the temporal attention; however, here the attention weights will be used inside a Graph convolution layer\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://i.ibb.co/stTfTFM/spat2.jpg\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "ckTvqtrIxXiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpatialAttention(nn.Module):\n",
        "    r\"\"\"    compute spatial attention scores\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        num_of_vertices (int): Number of vertices in the graph.\n",
        "        num_of_timesteps (int): Number of time lags.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, num_of_vertices: int, num_of_timesteps: int, DEVICE = torch.device('cuda:0')):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        self._W1 = nn.Parameter(torch.cuda.FloatTensor(num_of_timesteps))  # (12)\n",
        "        self._W2 = nn.Parameter(torch.cuda.FloatTensor(in_channels, num_of_timesteps))   # (1, 12)\n",
        "        self._W3 = nn.Parameter(torch.cuda.FloatTensor(in_channels))  # (1)\n",
        "        self._bs = nn.Parameter(torch.cuda.FloatTensor(1, num_of_vertices, num_of_vertices))   #(1,307, 307)\n",
        "        self._Vs = nn.Parameter(torch.cuda.FloatTensor(num_of_vertices, num_of_vertices))  # (307, 307)\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "            else:\n",
        "                nn.init.uniform_(p)\n",
        "    \n",
        "    def forward(self, X: torch.FloatTensor) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Making a forward pass of the spatial attention layer.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (PyTorch FloatTensor) - Node features for T time periods, with shape (B, N_nodes, F_in, T_in).\n",
        "\n",
        "        Return types:\n",
        "            * **S** (PyTorch FloatTensor) - Spatial attention score matrices, with shape (B, N_nodes, N_nodes).\n",
        "        \"\"\"\n",
        "\n",
        "        LHS = torch.matmul(torch.matmul(X, self._W1), self._W2) # (b,N,F,T)(T)->(b,N,F)(F,T)->(b,N,T) (32, 307, 12)\n",
        "        RHS = torch.matmul(self._W3, X).transpose(-1, -2) # (F)(b,N,F,T)->(b,N,T)->(b,T,N) (32, 12, 307)\n",
        "        S = torch.matmul(self._Vs, torch.sigmoid(torch.matmul(LHS, RHS) + self._bs))  # (b,N,T)(b,T,N) -> (B, N, N) (32, 307, 307)\n",
        "         # (N,N)(B, N, N)->(B,N,N) (32, 307, 307)\n",
        "        S = F.softmax(S, dim=1)\n",
        "        return S"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.193368Z",
          "iopub.execute_input": "2021-12-24T18:45:39.193973Z",
          "iopub.status.idle": "2021-12-24T18:45:39.209236Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.193937Z",
          "shell.execute_reply": "2021-12-24T18:45:39.208321Z"
        },
        "trusted": true,
        "id": "9w7G7tF2xXiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spectral graph analysis on the spatial part\n",
        "Since the spatial part is represented as a graph, we will apply graph convolution to aggregate messages from neighbor nodes. The type of graph convolution that we are going to use is spectral convolution. \n",
        "\n",
        "* In spectral graph analysis, a graph is represented by its corresponding Laplacian matrix. \n",
        "* The properties of the graph structure can be obtained by analyzing Laplacian matrix and its eigenvalues\n",
        "\n",
        "* Laplacian matrix of a graph is defined as L = D − A, \n",
        "\n",
        "* Its normalized form is L = I − ((1/ sqrt(D) A ( 1/ sqrt(D))  \n",
        "\n",
        "where A is the adjacent matrix, I is a unit matrix, and the degree matrix D (diagnoal diagonal matrix, consisting of node degrees,at the diagonal) \n",
        "\n",
        "The eigenvalue decomposition of the Laplacian matrix is L = U*Λ*(U.transpose()) , where Λ = diag([λ0, ..., λN −1]) is a diagonal matrix, and U is Fourier basis. \n",
        "\n",
        "U is an orthogonal matrix.\n",
        "\n",
        "The graph convolution is a convolution operation implemented by using linear operators that diagonalize in the Fourier domain to replace the classical convolution operator.\n",
        "\n",
        "However, it is expensive to directly perform the eigenvalue decomposition on the Laplacian matrix when the scale of the graph is large. Therefore, Chebyshev polynomials are adopted to solve this problem approximately but efficiently. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J3vWUQ0BxXiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "66uf1WPvxXiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Compute graph Laplacian\n",
        "The first step is to  computes the graph Laplacian of the graph given by edge_index and optional edge_weight.\n",
        "\n"
      ],
      "metadata": {
        "id": "BC94olSFxXir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChebConvAttention(MessagePassing):\n",
        "    r\"\"\"The chebyshev spectral graph convolutional operator with attention from the\n",
        "    `Attention Based Spatial-Temporal Graph Convolutional\n",
        "    Networks for Traffic Flow Forecasting.\" <https://ojs.aaai.org/index.php/AAAI/article/view/3881>`_ paper\n",
        "    :math:`\\mathbf{\\hat{L}}` denotes the scaled and normalized Laplacian\n",
        "    :math:`\\frac{2\\mathbf{L}}{\\lambda_{\\max}} - \\mathbf{I}`.\n",
        "    K-order chebyshev graph convolution\n",
        "    Args:\n",
        "        in_channels (int): Size of each input sample. num of channels in the input sequence\n",
        "        out_channels (int): Size of each output sample. num of channels in the output sequence\n",
        "        K (int): Chebyshev filter size :math:`K`.\n",
        "        normalization (str, optional): The normalization scheme for the graph\n",
        "            Laplacian (default: :obj:`\"sym\"`):\n",
        "            1. :obj:`None`: No normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
        "            2. :obj:`\"sym\"`: Symmetric normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
        "            \\mathbf{D}^{-1/2}`\n",
        "            3. :obj:`\"rw\"`: Random-walk normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
        "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
        "            this operator in case the normalization is non-symmetric.\n",
        "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
        "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
        "            scalar/zero-dimensional tensor when operating on single graphs.\n",
        "            You can pre-compute :obj:`lambda_max` via the\n",
        "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "        **kwargs (optional): Additional arguments of\n",
        "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int,out_channels: int,K: int, normalization: Optional[str] = None, bias: bool = True,**kwargs):\n",
        "        kwargs.setdefault(\"aggr\", \"add\")\n",
        "        super(ChebConvAttention, self).__init__(**kwargs)\n",
        "        assert K > 0\n",
        "        assert normalization in [None, \"sym\", \"rw\"], \"Invalid normalization\"\n",
        "\n",
        "        self._in_channels = in_channels\n",
        "        self._out_channels = out_channels\n",
        "        self._normalization = normalization\n",
        "        self._weight = Parameter(torch.Tensor(K, in_channels, out_channels))  #    self.Theta  [3, 1, 64]\n",
        "        if bias:\n",
        "            self._bias = Parameter(torch.Tensor(out_channels))\n",
        "        else:\n",
        "            self.register_parameter(\"_bias\", None)\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self._weight)\n",
        "        if self._bias is not None:\n",
        "            nn.init.uniform_(self._bias)\n",
        "#------------------------------------------------------------forward\n",
        "    def __norm__( self, edge_index, num_nodes: Optional[int], edge_weight: OptTensor,normalization: Optional[str],  lambda_max, \n",
        "                 dtype: Optional[int] = None, batch: OptTensor = None ):\n",
        "\n",
        "\n",
        "        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n",
        "\n",
        "        edge_index, edge_weight = get_laplacian(edge_index, edge_weight, normalization, dtype, num_nodes)\n",
        "\n",
        "        if batch is not None and lambda_max.numel() > 1:\n",
        "            lambda_max = lambda_max[batch[edge_index[0]]]\n",
        "\n",
        "        edge_weight = (2.0 * edge_weight) / lambda_max\n",
        "        edge_weight.masked_fill_(edge_weight == float(\"inf\"), 0)\n",
        "        #edge_index, edge_weight = add_self_loops( edge_index, edge_weight, fill_value=-1.0, num_nodes=num_nodes )\n",
        "        assert edge_weight is not None\n",
        "        return edge_index, edge_weight # 307 nodes as deg, 340 edges , 307 nodes as self connections\n",
        "\n",
        "    \n",
        "    def forward(self, x: torch.FloatTensor, edge_index: torch.LongTensor, spatial_attention: torch.FloatTensor, \n",
        "                edge_weight: OptTensor = None, batch: OptTensor = None, lambda_max: OptTensor = None,) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Making a forward pass of the ChebConv Attention layer.(Chebyshev graph convolution operation)\n",
        "\n",
        "        Arg types:\n",
        "            * x (PyTorch Float Tensor) - Node features for T time periods, with shape (B, N_nodes, F_in).\n",
        "            * edge_index (Tensor array) - Edge indices.\n",
        "            * spatial_attention (PyTorch Float Tensor) - Spatial attention weights, with shape (B, N_nodes, N_nodes).\n",
        "            * edge_weight (PyTorch Float Tensor, optional) - Edge weights corresponding to edge indices.\n",
        "            * batch (PyTorch Tensor, optional) - Batch labels for each edge.\n",
        "            * lambda_max (optional, but mandatory if normalization is None) - Largest eigenvalue of Laplacian.\n",
        "\n",
        "        Return types:\n",
        "            * out (PyTorch Float Tensor) - Hidden state tensor for all nodes, with shape (B, N_nodes, F_out).\n",
        "        \"\"\"\n",
        "        if self._normalization != \"sym\" and lambda_max is None:\n",
        "            raise ValueError( \"You need to pass `lambda_max` to `forward() in case the normalization is non-symmetric.\")\n",
        "\n",
        "        if lambda_max is None:\n",
        "            lambda_max = torch.tensor(2.0, dtype=x.dtype, device=x.device)\n",
        "        if not isinstance(lambda_max, torch.Tensor):\n",
        "            lambda_max = torch.tensor(lambda_max, dtype=x.dtype, device=x.device)\n",
        "        assert lambda_max is not None\n",
        "\n",
        "        edge_index, norm = self.__norm__(edge_index, x.size(self.node_dim), edge_weight, self._normalization, lambda_max, \n",
        "                                         dtype=x.dtype, batch=batch)\n",
        "        row, col = edge_index # refer to the index of each note each is a list of nodes not a number # (954, 954)\n",
        "        \n",
        "        Att_norm = norm * spatial_attention[:, row, col] # spatial_attention (32, 307, 307), -> (954) * (32, 954) -> (32, 954)\n",
        "\n",
        "        num_nodes = x.size(self.node_dim) # 307\n",
        "        # (307, 307) * (32, 307, 307) -> (32, 307, 307) -permute-> (32, 307,307) * (32, 307, 1) -> (32, 307, 1)\n",
        "        TAx_0 = torch.matmul((torch.eye(num_nodes).to(edge_index.device) * spatial_attention).permute( 0, 2, 1), x) # (32, 307, 1)\n",
        "        out = torch.matmul(TAx_0, self._weight[0]) # (32, 307, 1) * [1, 64] -> (32, 307, 64)\n",
        "        edge_index_transpose = edge_index[[1, 0]]\n",
        "        if self._weight.size(0) > 1: # Do once\n",
        "            TAx_1 = self.propagate( edge_index_transpose, x=TAx_0, norm=Att_norm, size=None)\n",
        "            out = out + torch.matmul(TAx_1, self._weight[1])\n",
        "\n",
        "        for k in range(2, self._weight.size(0)): # Do once\n",
        "            TAx_2 = self.propagate(edge_index_transpose, x=TAx_1, norm=norm, size=None)\n",
        "            TAx_2 = 2.0 * TAx_2 - TAx_0\n",
        "            out = out + torch.matmul(TAx_2, self._weight[k])\n",
        "            TAx_0, TAx_1 = TAx_1, TAx_2\n",
        "\n",
        "        if self._bias is not None:\n",
        "            out += self._bias\n",
        "        return out #? (b, N, F_out) (32, 307, 64)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        if norm.dim() == 1: # do this\n",
        "            return norm.view(-1, 1) * x_j  # (954, 1) * (32, 954, 1) -> (32, 954, 1)\n",
        "        else:\n",
        "            d1, d2 = norm.shape\n",
        "            return norm.view(d1, d2, 1) * x_j\n",
        "\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"{}({}, {}, K={}, normalization={})\".format(self.__class__.__name__,self._in_channels,self._out_channels,self._weight.size(0),self._normalization,)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.210827Z",
          "iopub.execute_input": "2021-12-24T18:45:39.21131Z",
          "iopub.status.idle": "2021-12-24T18:45:39.244597Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.211274Z",
          "shell.execute_reply": "2021-12-24T18:45:39.243825Z"
        },
        "trusted": true,
        "id": "F3kjh5GnxXis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The ASTGCN block"
      ],
      "metadata": {
        "id": "8LQDur7yxXiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ASTGCNBlock(nn.Module):\n",
        "    r\"\"\"\n",
        "    Args:\n",
        "        in_channels (int): Number of input features.\n",
        "        K (int): Order of Chebyshev polynomials. Degree is K-1.\n",
        "        nb_chev_filter (int): Number of Chebyshev filters.\n",
        "        nb_time_filter (int): Number of time filters.\n",
        "        time_strides (int): Time strides during temporal convolution.\n",
        "        num_of_vertices (int): Number of vertices in the graph.\n",
        "        num_of_timesteps (int): Number of time lags.\n",
        "        normalization (str, optional): The normalization scheme for the graph\n",
        "            Laplacian (default: :obj:`\"sym\"`):\n",
        "            1. :obj:`None`: No normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
        "            2. :obj:`\"sym\"`: Symmetric normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
        "            \\mathbf{D}^{-1/2}`\n",
        "            3. :obj:`\"rw\"`: Random-walk normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
        "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
        "            this operator in case the normalization is non-symmetric.\n",
        "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
        "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
        "            scalar/zero-dimensional tensor when operating on single graphs.\n",
        "            You can pre-compute :obj:`lambda_max` via the\n",
        "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels: int,K: int,nb_chev_filter: int,nb_time_filter: int,time_strides: int,num_of_vertices: int,\n",
        "        num_of_timesteps: int,normalization: Optional[str] = None,bias: bool = True, DEVICE = torch.device('cuda:0')):\n",
        "        super(ASTGCNBlock, self).__init__()\n",
        "\n",
        "        self._temporal_attention = TemporalAttention(in_channels, num_of_vertices, num_of_timesteps, DEVICE)\n",
        "        self._spatial_attention = SpatialAttention(in_channels, num_of_vertices, num_of_timesteps, DEVICE)\n",
        "        self._chebconv_attention = ChebConvAttention(in_channels, nb_chev_filter, K, normalization, bias)\n",
        "        self._time_convolution = nn.Conv2d( nb_chev_filter,nb_time_filter,kernel_size=(1, 3), stride=(1, time_strides),padding=(0, 1))\n",
        "        self._residual_convolution = nn.Conv2d(in_channels, nb_time_filter, kernel_size=(1, 1), stride=(1, time_strides))\n",
        "        self._layer_norm = nn.LayerNorm(nb_time_filter) #channel\n",
        "        self._normalization = normalization\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "            else:\n",
        "                nn.init.uniform_(p)\n",
        "\n",
        "    def forward(self, X: torch.FloatTensor, edge_index: Union[torch.LongTensor, List[torch.LongTensor]]) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Making a forward pass with the ASTGCN block.\n",
        "        Arg types:\n",
        "            * **X** (PyTorch Float Tensor) - Node features for T time periods, with shape (B, N_nodes, F_in, T_in).\n",
        "            * **edge_index** (LongTensor): Edge indices, can be an array of a list of Tensor arrays, depending on whether edges change over time.\n",
        "\n",
        "        Return types:\n",
        "            * **X** (PyTorch Float Tensor) - Hidden state tensor for all nodes, with shape (B, N_nodes, nb_time_filter, T_out).\n",
        "        \"\"\"\n",
        "        batch_size, num_of_vertices, num_of_features, num_of_timesteps = X.shape  # (32, 307, 1, 12)\n",
        "        X_tilde = self._temporal_attention(X) # (b, T, T)  (32, 12, 12) * reshaped x(32, 307, 12)  -reshape> (32, 307, 1, 12)\n",
        "        X_tilde = torch.matmul(X.reshape(batch_size, -1, num_of_timesteps), X_tilde)\n",
        "        X_tilde = X_tilde.reshape(batch_size, num_of_vertices, num_of_features, num_of_timesteps)\n",
        "        X_tilde = self._spatial_attention(X_tilde) # (32, 307, 307)\n",
        "\n",
        "        if not isinstance(edge_index, list):\n",
        "            data = Data(edge_index=edge_index, edge_attr=None, num_nodes=num_of_vertices)\n",
        "            if self._normalization != \"sym\":\n",
        "                lambda_max = LaplacianLambdaMax()(data).lambda_max\n",
        "            else:\n",
        "                lambda_max = None\n",
        "            X_hat = []\n",
        "            for t in range(num_of_timesteps):\n",
        "                X_hat.append(torch.unsqueeze( self._chebconv_attention(X[:, :, :, t], edge_index, X_tilde, lambda_max=lambda_max), -1))\n",
        "\n",
        "            X_hat = F.relu(torch.cat(X_hat, dim=-1))\n",
        "        else:\n",
        "            X_hat = []\n",
        "            for t in range(num_of_timesteps):\n",
        "                data = Data(edge_index=edge_index[t], edge_attr=None, num_nodes=num_of_vertices)\n",
        "                if self._normalization != \"sym\":\n",
        "                    lambda_max = LaplacianLambdaMax()(data).lambda_max\n",
        "                else:\n",
        "                    lambda_max = None\n",
        "                X_hat.append(torch.unsqueeze(self._chebconv_attention(X[:, :, :, t], edge_index[t], X_tilde, lambda_max=lambda_max),-1,))\n",
        "            X_hat = F.relu(torch.cat(X_hat, dim=-1))\n",
        "\n",
        "        # (b,N,F,T) (32, 307, 64, 12) -premute->(32, 64, 307,12)\n",
        "        # convolution along the time axis\n",
        "        X_hat = self._time_convolution(X_hat.permute(0, 2, 1, 3))   # (b,N,F,T)->(b,F,N,T) (1,3)->(b,F,N,T) (32, 64, 307, 12)\n",
        "        X = self._residual_convolution(X.permute(0, 2, 1, 3)) # (b,N,F,T)->(b,F,N,T) (1,1)->(b,F,N,T)  (32, 64, 307, 12)\n",
        "        #-adding->(32, 64, 307, 12)-premuting-> (32, 12, 307, 64)-layer_normalization_-premuting->(32, 307, 64,12) \n",
        "        X = self._layer_norm(F.relu(X + X_hat).permute(0, 3, 2, 1))\n",
        "        X = X.permute(0, 2, 3, 1)\n",
        "        # (b,F,N,T)->(b,T,N,F) -ln-> (b,T,N,F)->(b,N,F,T)\n",
        "        return X"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.245805Z",
          "iopub.execute_input": "2021-12-24T18:45:39.246268Z",
          "iopub.status.idle": "2021-12-24T18:45:39.276077Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.246229Z",
          "shell.execute_reply": "2021-12-24T18:45:39.274168Z"
        },
        "trusted": true,
        "id": "JMN21jlixXix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The ASTGCN model structure\n",
        "\n",
        "\n",
        "The model is composed of two ASTGCN blocks followed by a final layer\n",
        "\n",
        "Original x (input) is (32, 307, 1, 12) -Block1> (32, 307, 64, 12) -Block2> (32, 307, 64, 12) -permute-> (32, 12, 307,64) \n",
        "            # -final_conv-> (32, 12, 307, 1) -reshape-> (32,307,12) \"The target\"\n",
        "            \n",
        "\n",
        "\n",
        "The model is  the fusion of three independent components with the same structure, which are designed to respectively model the recent, daily-periodic and weekly-periodic dependencies of the historical data. This is discussed in the previous notebook (https://www.kaggle.com/elmahy/processing-traffic-data-for-deep-learning-projects). \n",
        "\n",
        "But in our case we will only focus on the recent segment (last hour segment) i.e. X_h  \n",
        "\n",
        "![astgcn.png](attachment:ec80c00c-6836-4449-85ba-e0b9d174a2f5.png)"
      ],
      "metadata": {
        "id": "21HqAFMyxXiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ASTGCN(nn.Module):\n",
        "    r\"\"\"An implementation of the Attention Based Spatial-Temporal Graph Convolutional Cell.\n",
        "    For details see this paper: `\"Attention Based Spatial-Temporal Graph Convolutional\n",
        "    Networks for Traffic Flow Forecasting.\" <https://ojs.aaai.org/index.php/AAAI/article/view/3881>`_\n",
        "\n",
        "    Args:\n",
        "        nb_block (int): Number of ASTGCN blocks in the model.\n",
        "        in_channels (int): Number of input features.\n",
        "        K (int): Order of Chebyshev polynomials. Degree is K-1.\n",
        "        nb_chev_filters (int): Number of Chebyshev filters.\n",
        "        nb_time_filters (int): Number of time filters.\n",
        "        time_strides (int): Time strides during temporal convolution.\n",
        "        edge_index (array): edge indices.\n",
        "        num_for_predict (int): Number of predictions to make in the future.\n",
        "        len_input (int): Length of the input sequence.\n",
        "        num_of_vertices (int): Number of vertices in the graph.\n",
        "        normalization (str, optional): The normalization scheme for the graph\n",
        "            Laplacian (default: :obj:`\"sym\"`):\n",
        "            1. :obj:`None`: No normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{D} - \\mathbf{A}`\n",
        "            2. :obj:`\"sym\"`: Symmetric normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1/2} \\mathbf{A}\n",
        "            \\mathbf{D}^{-1/2}`\n",
        "            3. :obj:`\"rw\"`: Random-walk normalization\n",
        "            :math:`\\mathbf{L} = \\mathbf{I} - \\mathbf{D}^{-1} \\mathbf{A}`\n",
        "            You need to pass :obj:`lambda_max` to the :meth:`forward` method of\n",
        "            this operator in case the normalization is non-symmetric.\n",
        "            :obj:`\\lambda_max` should be a :class:`torch.Tensor` of size\n",
        "            :obj:`[num_graphs]` in a mini-batch scenario and a\n",
        "            scalar/zero-dimensional tensor when operating on single graphs.\n",
        "            You can pre-compute :obj:`lambda_max` via the\n",
        "            :class:`torch_geometric.transforms.LaplacianLambdaMax` transform.\n",
        "        bias (bool, optional): If set to :obj:`False`, the layer will not learn\n",
        "            an additive bias. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "        \n",
        "        \n",
        "    def __init__( self,  nb_block: int, in_channels: int,  K: int, nb_chev_filter: int,  nb_time_filter: int,  time_strides: int,\n",
        "        num_for_predict: int,len_input: int, num_of_vertices: int, normalization: Optional[str] = None,bias: bool = True, DEVICE = torch.device('cuda:0')):\n",
        "\n",
        "        super(ASTGCN, self).__init__()\n",
        "\n",
        "        self._blocklist = nn.ModuleList([ASTGCNBlock( in_channels, K, nb_chev_filter, nb_time_filter,time_strides, num_of_vertices, \n",
        "                                                     len_input, normalization,bias, DEVICE)])\n",
        "\n",
        "        self._blocklist.extend( [ASTGCNBlock( nb_time_filter,  K, nb_chev_filter, nb_time_filter, 1, num_of_vertices, \n",
        "                                             len_input // time_strides, normalization,  bias, DEVICE)  for _ in range(nb_block - 1) ]) # nb_block= 2\n",
        "\n",
        "        self._final_conv = nn.Conv2d( int(len_input / time_strides),   num_for_predict,  kernel_size=(1, nb_time_filter))\n",
        "\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Resetting the parameters.\n",
        "        \"\"\"\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "            else:\n",
        "                nn.init.uniform_(p)\n",
        "                \n",
        "\n",
        "    def forward(  self, X: torch.FloatTensor, edge_index: torch.LongTensor ) -> torch.FloatTensor:\n",
        "        \"\"\"\n",
        "        Making a forward pass.\n",
        "\n",
        "        Arg types:\n",
        "            * **X** (PyTorch FloatTensor) - Node features for T time periods, with shape (B, N_nodes, F_in, T_in).\n",
        "            * **edge_index** (PyTorch LongTensor): Edge indices, can be an array of a list of Tensor arrays, depending on whether edges change over time.\n",
        "\n",
        "        Return types:\n",
        "            * **X** (PyTorch FloatTensor)* - Hidden state tensor for all nodes, with shape (B, N_nodes, T_out).\n",
        "        \"\"\"\n",
        "        for block in self._blocklist:\n",
        "            X = block(X, edge_index) # original x is (32, 307, 1, 12) -> (32, 307, 64, 12) -> (32, 307, 64, 12) -permute-> (32, 12, 307,64) \n",
        "            # -final_conv-> (32, 12, 307, 1)\n",
        "\n",
        "        X = self._final_conv(X.permute(0, 3, 1, 2))\n",
        "        X = X[:, :, :, -1]\n",
        "        X = X.permute(0, 2, 1) \n",
        "        # (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T) \n",
        "        return X # (32, 307, 12)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.277497Z",
          "iopub.execute_input": "2021-12-24T18:45:39.278028Z",
          "iopub.status.idle": "2021-12-24T18:45:39.294958Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.277998Z",
          "shell.execute_reply": "2021-12-24T18:45:39.293943Z"
        },
        "trusted": true,
        "id": "q5bXbX8jxXi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialized the ASTGCN model\n"
      ],
      "metadata": {
        "id": "9bb8h9VZxXi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_block = 2\n",
        "in_channels = 1\n",
        "K = 3\n",
        "nb_chev_filter = 64\n",
        "nb_time_filter = 64\n",
        "time_strides = 1 #num_of_hours\n",
        "num_for_predict = 24\n",
        "len_input = 72\n",
        "num_of_vertices = 84\n",
        "#L_tilde = scaled_Laplacian(adj_mx)\n",
        "#cheb_polynomials = [torch.from_numpy(i).type(torch.FloatTensor).to(DEVICE) for i in cheb_polynomial(L_tilde, K)]\n",
        "net = ASTGCN( nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, num_for_predict, len_input, num_of_vertices).to(DEVICE)\n",
        "\n",
        "print(net)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.296554Z",
          "iopub.execute_input": "2021-12-24T18:45:39.297178Z",
          "iopub.status.idle": "2021-12-24T18:45:39.330966Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.297138Z",
          "shell.execute_reply": "2021-12-24T18:45:39.330157Z"
        },
        "trusted": true,
        "id": "IACarO-IxXi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------\n",
        "learning_rate = 0.0001\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "print('Net\\'s state_dict:')\n",
        "total_param = 0\n",
        "for param_tensor in net.state_dict():\n",
        "    print(param_tensor, '\\t', net.state_dict()[param_tensor].size())\n",
        "    total_param += np.prod(net.state_dict()[param_tensor].size())\n",
        "print('Net\\'s total params:', total_param)\n",
        "#--------------------------------------------------\n",
        "print('Optimizer\\'s state_dict:')\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, '\\t', optimizer.state_dict()[var_name])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.332282Z",
          "iopub.execute_input": "2021-12-24T18:45:39.332828Z",
          "iopub.status.idle": "2021-12-24T18:45:39.387649Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.332791Z",
          "shell.execute_reply": "2021-12-24T18:45:39.387002Z"
        },
        "trusted": true,
        "id": "L1Edn6yyxXi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the loss function\n",
        "\n",
        " 1. masked_mae"
      ],
      "metadata": {
        "id": "rz9oLlvixXi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_mae(preds, labels, null_val=np.nan):\n",
        "    if np.isnan(null_val):\n",
        "        mask = ~torch.isnan(labels)\n",
        "    else:\n",
        "        mask = (labels != null_val)\n",
        "    mask = mask.float()\n",
        "    mask /= torch.mean((mask))\n",
        "    mask = torch.where(torch.isnan(mask), torch.zeros_like(mask), mask)\n",
        "    loss = torch.abs(preds - labels)\n",
        "    loss = loss * mask\n",
        "    loss = torch.where(torch.isnan(loss), torch.zeros_like(loss), loss)\n",
        "    return torch.mean(loss)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.390661Z",
          "iopub.execute_input": "2021-12-24T18:45:39.390899Z",
          "iopub.status.idle": "2021-12-24T18:45:39.397807Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.390875Z",
          "shell.execute_reply": "2021-12-24T18:45:39.396903Z"
        },
        "trusted": true,
        "id": "aQD4ZOLKxXi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_flag=0\n",
        "criterion = nn.L1Loss().to(DEVICE)\n",
        "criterion_masked = masked_mae\n",
        "loss_function = 'mse'\n",
        "\n",
        "metric_method = 'unmask'\n",
        "missing_value=0.0\n",
        "\n",
        "loss_function = 'rmse'\n",
        "if loss_function=='masked_mse':\n",
        "    criterion_masked = masked_mse         #nn.MSELoss().to(DEVICE)\n",
        "    masked_flag=1\n",
        "elif loss_function=='masked_mae':\n",
        "    criterion_masked = masked_mae\n",
        "    masked_flag = 1\n",
        "elif loss_function == 'mae':\n",
        "    criterion = nn.L1Loss().to(DEVICE)\n",
        "    masked_flag = 0\n",
        "elif loss_function == 'rmse':\n",
        "    criterion = nn.MSELoss().to(DEVICE)\n",
        "    masked_flag= 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.399569Z",
          "iopub.execute_input": "2021-12-24T18:45:39.40004Z",
          "iopub.status.idle": "2021-12-24T18:45:39.410125Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.39987Z",
          "shell.execute_reply": "2021-12-24T18:45:39.409256Z"
        },
        "trusted": true,
        "id": "yRoQKmZVxXi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.411432Z",
          "iopub.execute_input": "2021-12-24T18:45:39.412011Z",
          "iopub.status.idle": "2021-12-24T18:45:39.422371Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.411973Z",
          "shell.execute_reply": "2021-12-24T18:45:39.421424Z"
        },
        "trusted": true,
        "id": "OMVSeakAxXi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "gykYqILJxXi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_val_loss_mstgcn(net, val_loader, criterion,  masked_flag,missing_value,sw, epoch, edge_index_data, limit=None):\n",
        "    '''\n",
        "    for rnn, compute mean loss on validation set\n",
        "    :param net: model\n",
        "    :param val_loader: torch.utils.data.utils.DataLoader\n",
        "    :param criterion: torch.nn.MSELoss\n",
        "    :param sw: tensorboardX.SummaryWriter\n",
        "    :param global_step: int, current global_step\n",
        "    :param limit: int,\n",
        "    :return: val_loss\n",
        "    '''\n",
        "    net.train(False)  # ensure dropout layers are in evaluation mode\n",
        "    with torch.no_grad():\n",
        "        val_loader_length = len(val_loader)  # nb of batch\n",
        "        tmp = []  # batch loss\n",
        "        for batch_index, batch_data in enumerate(val_loader):\n",
        "            encoder_inputs, labels = batch_data\n",
        "            outputs = net(encoder_inputs, edge_index_data)\n",
        "            if masked_flag:\n",
        "                loss = criterion(outputs, labels, missing_value)\n",
        "            else:\n",
        "                loss = criterion(outputs, labels)\n",
        "            tmp.append(loss.item())\n",
        "            if batch_index % 100 == 0:\n",
        "                print('validation batch %s / %s, loss: %.2f' % (batch_index + 1, val_loader_length, loss.item()))\n",
        "            if (limit is not None) and batch_index >= limit:\n",
        "                break\n",
        "\n",
        "        validation_loss = sum(tmp) / len(tmp)\n",
        "        sw.add_scalar('validation_loss', validation_loss, epoch)\n",
        "    return validation_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.423747Z",
          "iopub.execute_input": "2021-12-24T18:45:39.424226Z",
          "iopub.status.idle": "2021-12-24T18:45:39.436752Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.424184Z",
          "shell.execute_reply": "2021-12-24T18:45:39.435691Z"
        },
        "trusted": true,
        "id": "-gBJI_OmxXi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_step = 0\n",
        "best_epoch = 0\n",
        "best_val_loss = np.inf\n",
        "start_time= time()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.438197Z",
          "iopub.execute_input": "2021-12-24T18:45:39.438457Z",
          "iopub.status.idle": "2021-12-24T18:45:39.445804Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.438434Z",
          "shell.execute_reply": "2021-12-24T18:45:39.445142Z"
        },
        "trusted": true,
        "id": "Zex0LiPXxXi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_flag"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.447128Z",
          "iopub.execute_input": "2021-12-24T18:45:39.448508Z",
          "iopub.status.idle": "2021-12-24T18:45:39.454842Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.44735Z",
          "shell.execute_reply": "2021-12-24T18:45:39.453692Z"
        },
        "trusted": true,
        "id": "sqoOXVD4xXi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "for epoch in range(10):\n",
        "    params_filename = os.path.join('./', 'epoch_%s.params' % epoch)\n",
        "    masked_flag = 1\n",
        "    if masked_flag:\n",
        "        val_loss = compute_val_loss_mstgcn(net, train_loader, criterion_masked, masked_flag,missing_value,sw, epoch,edge_index_data)\n",
        "    else:\n",
        "        val_loss = compute_val_loss_mstgcn(net, train_loader, criterion, masked_flag, missing_value, sw, epoch,edge_index_data)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "        torch.save(net.state_dict(), params_filename)\n",
        "        print('save parameters to file: %s' % params_filename)\n",
        "\n",
        "    net.train()  # ensure dropout layers are in train mode\n",
        "    for _ in range(10):\n",
        "        for batch_index, batch_data in enumerate(train_loader):\n",
        "            encoder_inputs, labels = batch_data   # encoder_inputs torch.Size([32, 307, 1, 12])  label torch.Size([32, 307, 12])\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(encoder_inputs, edge_index_data) # torch.Size([32, 307, 12])\n",
        "\n",
        "            if masked_flag:\n",
        "                loss = criterion_masked(outputs, labels,missing_value)\n",
        "            else :\n",
        "                loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss = loss.item()\n",
        "            global_step += 1\n",
        "            sw.add_scalar('training_loss', training_loss, global_step)\n",
        "\n",
        "            if global_step % 50 == 0:\n",
        "                print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step, training_loss, time() - start_time))\n",
        "            if global_step % 200 == 0:\n",
        "                #plt.plot(np.concatenate([encoder_inputs[0][0][0].cpu().numpy(), labels[0][0].cpu().numpy()]))\n",
        "                plt.plot(range(72),encoder_inputs[0][0][0].cpu().numpy(), color = 'red')\n",
        "                plt.plot(range(72,96), labels[0][0].cpu().numpy(), color='blue')\n",
        "                plt.show()\n",
        "                plt.plot(range(72),encoder_inputs[0][0][0].cpu().numpy(), color = 'red')\n",
        "                plt.plot(range(72,96), outputs[0][0].detach().cpu().numpy(), color='blue')\n",
        "                plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:45:39.456484Z",
          "iopub.execute_input": "2021-12-24T18:45:39.457225Z",
          "iopub.status.idle": "2021-12-24T18:49:21.425348Z",
          "shell.execute_reply.started": "2021-12-24T18:45:39.457187Z",
          "shell.execute_reply": "2021-12-24T18:49:21.423285Z"
        },
        "trusted": true,
        "id": "ikGp6SeLxXi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the model"
      ],
      "metadata": {
        "id": "IYwiR4V0xXjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.train(False)  # ensure dropout layers are in evaluation mode\n",
        "with torch.no_grad():\n",
        "    test_loader_length = len(test_loader)  # nb of batch\n",
        "    tmp = []  # batch loss\n",
        "    for batch_index, batch_data in enumerate(test_loader):\n",
        "        encoder_inputs, labels = batch_data\n",
        "        outputs = net(encoder_inputs, edge_index_data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        tmp.append(loss.item())\n",
        "        if batch_index % 100 == 0:\n",
        "            print('test_loss batch %s / %s, loss: %.2f' % (batch_index + 1, test_loader_length, loss.item()))\n",
        "\n",
        "\n",
        "    test_loss = sum(tmp) / len(tmp)\n",
        "    sw.add_scalar('test_loss', test_loss, epoch)\n",
        "print(test_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:49:48.088837Z",
          "iopub.execute_input": "2021-12-24T18:49:48.089215Z",
          "iopub.status.idle": "2021-12-24T18:49:50.161401Z",
          "shell.execute_reply.started": "2021-12-24T18:49:48.089181Z",
          "shell.execute_reply": "2021-12-24T18:49:50.160436Z"
        },
        "trusted": true,
        "id": "B1SLYcG2xXjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "\n",
        "figure(figsize=(30,4), dpi=80)\n",
        "for i in range(84):\n",
        "    new_i = i * 24\n",
        "    plt.plot(range(0+new_i,24+new_i),outputs[0][i].detach().cpu().numpy(), color = 'red')\n",
        "    plt.plot(range(0+new_i,24+new_i), labels[0][i].cpu().numpy(), color='blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-12-24T18:49:29.06592Z",
          "iopub.execute_input": "2021-12-24T18:49:29.066286Z",
          "iopub.status.idle": "2021-12-24T18:49:29.488854Z",
          "shell.execute_reply.started": "2021-12-24T18:49:29.066248Z",
          "shell.execute_reply": "2021-12-24T18:49:29.487891Z"
        },
        "trusted": true,
        "id": "Y_BtfsZrxXjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zZbbTXeAxXjC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}